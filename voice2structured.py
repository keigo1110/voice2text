"""
voice2structured: éŸ³å£°æ–‡å­—èµ·ã“ã—å°‚ç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»¥ä¸‹ã®2ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã§æ–‡å­—èµ·ã“ã—ï¼š
1. transcript: è¬›æ¼”ã‚„è­°è«–ã®æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—ï¼ˆè©±è€…ä¸€è²«æ€§ä¿æŒï¼‰
2. lifelog: æ—¥å¸¸éŸ³å£°ã‹ã‚‰è¡Œå‹•æ¨è«–ã‚’å«ã‚€è©³ç´°è¨˜éŒ²

ç‰¹å¾´ï¼š
- è©±è€…ã®ä¸€è²«æ€§ç®¡ç†
- è©³ç´°ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ä¿æŒ
- ãƒãƒ£ãƒ³ã‚¯é–“ã®æ–‡è„ˆä¿å­˜å¼·åŒ–
- ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½
- ç´”ç²‹ãªæ–‡å­—èµ·ã“ã—ã«ç‰¹åŒ–ï¼ˆæ§‹é€ åŒ–å¤‰æ›ã¯/formatã§å®Ÿè¡Œï¼‰

ä½¿ç”¨ä¾‹:
    # å…¨æ–‡æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    python voice2structured.py audio.wav --mode transcript

    # ãƒ©ã‚¤ãƒ•ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰
    python voice2structured.py audio.wav --mode lifelog

    # ä¸­æ–­ã—ãŸå‡¦ç†ã®å†é–‹
    python voice2structured.py audio.wav --resume
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union, Set
import yaml
import json
import re
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict, field
import argparse
import pickle

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from prompts_transcript import (
        SYSTEM_PROMPT_TRANSCRIPT_CHUNK,
        USER_PROMPT_TRANSCRIPT_CHUNK,
    )
    from prompts_lifelog import (
        SYSTEM_PROMPT_LIFELOG_CHUNK,
        USER_PROMPT_LIFELOG_CHUNK,
    )
except ImportError as e:
    print(f"Error: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("prompts_transcript.py ã¨ prompts_lifelog.py ãŒå¿…è¦ã§ã™ã€‚")
    sys.exit(1)

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import google.generativeai as genai
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
except ImportError:
    print(
        "Error: google-generativeai not found. Install with: pip install google-generativeai"
    )
    sys.exit(1)

try:
    from pydub import AudioSegment
    from pydub.silence import detect_nonsilent
except ImportError:
    print("Error: pydub not found. Install with: pip install pydub")
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("voice2structured.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


@dataclass
class GeminiAPIConfig:
    """Gemini APIè¨­å®š"""

    api_key: str = ""
    base_url: str = ""
    timeout_sec: int = 120
    max_retries: int = 3


@dataclass
class GeminiModelConfig:
    """Geminiãƒ¢ãƒ‡ãƒ«è¨­å®š"""

    name: str = "gemini-2.5-flash"
    fallback_models: List[str] = field(
        default_factory=lambda: ["gemini-1.5-flash", "gemini-1.5-pro"]
    )
    generation_config: Dict = field(
        default_factory=lambda: {
            "temperature": 0.1,
            "top_p": 0.9,
            "top_k": 40,
            "max_output_tokens": 8192,
        }
    )
    safety_settings: Dict = field(
        default_factory=lambda: {
            "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
            "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
            "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE",
            "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
        }
    )


@dataclass
class ProcessingConfig:
    """å‡¦ç†è¨­å®š"""

    chunk_duration_min: int = 8  # åˆ†ï¼ˆã‚ˆã‚Šå®‰å…¨ãªã‚µã‚¤ã‚ºï¼‰
    chunk_duration_max: int = 12  # åˆ†ï¼ˆAPIåˆ¶é™ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å›é¿ï¼‰
    target_tokens: int = 15000  # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›
    hard_token_cap: int = 20000  # ã‚ˆã‚Šå³ã—ã„åˆ¶é™
    max_concurrency: int = 3
    rolling_summary_tokens: int = 1000
    retry_max_attempts: int = 5
    retry_backoff_sec: int = 2
    retry_exponential_backoff: bool = True
    cost_budget_usd: float = 5.0
    cost_warn_threshold_usd: float = 4.0


@dataclass
class OutputConfig:
    """å‡ºåŠ›è¨­å®š"""

    mode: str = "transcript"  # transcript or lifelog
    output_dir: str = "./outputs"


@dataclass
class ChunkMetadata:
    """ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""

    chunk_id: int
    start_time: float
    end_time: float
    duration: float
    file_path: str
    tokens_estimated: int
    status: str = "pending"  # pending, processing, completed, failed


@dataclass
class EnhancedContext:
    """æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±"""

    rolling_summary: str = ""
    speaker_mapping: Dict[str, str] = field(default_factory=dict)
    speaker_descriptions: Dict[str, str] = field(default_factory=dict)
    key_topics: List[str] = field(default_factory=list)
    unresolved_references: List[str] = field(default_factory=list)
    key_decisions: List[str] = field(default_factory=list)
    action_items: List[Dict] = field(default_factory=list)
    current_topic: str = ""
    last_speakers: List[str] = field(default_factory=list)  # æœ€è¿‘ã®è©±è€…å±¥æ­´


@dataclass
class ProcessingState:
    """å‡¦ç†çŠ¶æ…‹ï¼ˆä¸­æ–­ãƒ»å†é–‹ç”¨ï¼‰"""

    audio_path: str
    mode: str
    completed_chunks: List[int] = field(default_factory=list)
    context: EnhancedContext = field(default_factory=EnhancedContext)
    results: List[Dict] = field(default_factory=list)
    timestamp: str = field(default_factory=str)


class Voice2Structured:
    """éŸ³å£°æ–‡å­—èµ·ã“ã—å°‚ç”¨ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆæœŸåŒ–

        Args:
            config_path: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.config_path = config_path
        self.config = self._load_config()

        # è¨­å®šã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        self.api_config = GeminiAPIConfig()
        self.model_config = GeminiModelConfig()
        self.processing_config = ProcessingConfig()
        self.output_config = OutputConfig()

        # è¨­å®šã‚’è§£æ
        self._parse_config()

        # Gemini APIè¨­å®š
        self._configure_gemini_api()
        self.model = self._create_gemini_model()

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.storage_dir = Path("./storage")
        self.temp_dir = self.storage_dir / "temp"
        self.chunks_dir = self.storage_dir / "chunks"
        self.transcripts_dir = self.storage_dir / "transcripts"
        self.checkpoints_dir = self.storage_dir / "checkpoints"

        for directory in [
            self.storage_dir,
            self.temp_dir,
            self.chunks_dir,
            self.transcripts_dir,
            self.checkpoints_dir,
        ]:
            directory.mkdir(parents=True, exist_ok=True)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
        self.context = EnhancedContext()

        # ç¾åœ¨å‡¦ç†ä¸­ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæ™‚åˆ»è¨ˆç®—ç”¨ï¼‰
        self.current_audio_path = None

        logger.info(
            f"Voice2Structured initialized with model: {self.model_config.name}"
        )

    def _load_config(self) -> Dict:
        """YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            if Path(self.config_path).exists():
                with open(self.config_path, "r", encoding="utf-8") as f:
                    return yaml.safe_load(f)
            else:
                logger.warning(
                    f"Config file {self.config_path} not found. Using defaults."
                )
                return {}
        except Exception as e:
            logger.error(f"Failed to load config: {e}")
            return {}

    def _parse_config(self):
        """è¨­å®šã®è§£æ"""
        # LLMè¨­å®š
        llm_config = self.config.get("llm", {})

        # APIè¨­å®š
        api_config = llm_config.get("api", {})
        self.api_config.api_key = api_config.get("api_key", "")
        self.api_config.base_url = api_config.get("base_url", "")
        self.api_config.timeout_sec = api_config.get("timeout_sec", 120)
        self.api_config.max_retries = api_config.get("max_retries", 3)

        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        model_config = llm_config.get("model", {})
        self.model_config.name = model_config.get("name", "gemini-2.5-flash")
        self.model_config.fallback_models = model_config.get(
            "fallback_models", ["gemini-1.5-flash", "gemini-1.5-pro"]
        )

        # ç”Ÿæˆè¨­å®š
        generation_config = model_config.get("generation_config", {})
        self.model_config.generation_config.update(generation_config)

        # å®‰å…¨è¨­å®š
        safety_settings = model_config.get("safety_settings", {})
        self.model_config.safety_settings.update(safety_settings)

        # å‡¦ç†è¨­å®š
        processing_config = llm_config.get("processing", {})
        self.processing_config.max_concurrency = processing_config.get(
            "max_concurrency", 3
        )
        self.processing_config.rolling_summary_tokens = processing_config.get(
            "rolling_summary_tokens", 1000
        )

        # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        retry_config = processing_config.get("retry", {})
        self.processing_config.retry_max_attempts = retry_config.get("max_attempts", 5)
        self.processing_config.retry_backoff_sec = retry_config.get("backoff_sec", 2)
        self.processing_config.retry_exponential_backoff = retry_config.get(
            "exponential_backoff", True
        )

        # ã‚³ã‚¹ãƒˆè¨­å®š
        cost_config = processing_config.get("cost_guard", {})
        self.processing_config.cost_budget_usd = cost_config.get("budget_usd", 5.0)
        self.processing_config.cost_warn_threshold_usd = cost_config.get(
            "warn_threshold_usd", 4.0
        )

        # ãƒãƒ£ãƒ³ã‚¯è¨­å®š
        chunk_config = self.config.get("chunk_policy", {})
        self.processing_config.chunk_duration_min = chunk_config.get("min_minutes", 30)
        self.processing_config.chunk_duration_max = chunk_config.get("max_minutes", 45)
        self.processing_config.target_tokens = chunk_config.get("target_tokens", 50000)
        self.processing_config.hard_token_cap = chunk_config.get(
            "hard_token_cap", 60000
        )

        # å‡ºåŠ›è¨­å®š
        io_config = self.config.get("io", {})
        input_config = io_config.get("input", {})
        self.output_config.mode = input_config.get("mode", "transcript")

        output_dir = io_config.get("output_dir", "./outputs")
        # ${job_id}ã‚’ç¾åœ¨æ™‚åˆ»ã§ç½®æ›
        job_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_config.output_dir = output_dir.replace("${job_id}", job_id)

    def _configure_gemini_api(self):
        """Gemini APIã®è¨­å®š"""
        # API Keyã®å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‚’å„ªå…ˆï¼‰
        api_key = os.getenv("GOOGLE_API_KEY") or self.api_config.api_key

        if not api_key:
            raise ValueError(
                "GOOGLE_API_KEY environment variable not found and no api_key in config"
            )

        # Gemini APIã®è¨­å®š
        genai.configure(api_key=api_key)

        logger.info("Gemini API configured successfully")

    def validate_configuration(self):
        """è¨­å®šã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []

        # API Keyç¢ºèª
        api_key = os.getenv("GOOGLE_API_KEY") or self.api_config.api_key
        if not api_key:
            issues.append(
                "âŒ GOOGLE_API_KEY environment variable or config.api_key not set"
            )
        else:
            issues.append("âœ… API Key found")

        # ãƒ¢ãƒ‡ãƒ«è¨­å®šç¢ºèª
        if self.model_config.name:
            issues.append(f"âœ… Model name: {self.model_config.name}")
        else:
            issues.append("âŒ Model name not configured")

        # ç”Ÿæˆè¨­å®šç¢ºèª
        gen_config = self.model_config.generation_config
        if gen_config.get("temperature", 0) < 0 or gen_config.get("temperature", 0) > 1:
            issues.append("âš ï¸  Temperature should be between 0.0 and 1.0")
        else:
            issues.append(f"âœ… Temperature: {gen_config.get('temperature', 0.1)}")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
        try:
            Path(self.output_config.output_dir.replace("${job_id}", "test")).mkdir(
                parents=True, exist_ok=True
            )
            issues.append("âœ… Output directory writable")
        except Exception as e:
            issues.append(f"âŒ Output directory not writable: {e}")

        return issues

    def _create_gemini_model(self):
        """Geminiãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"""
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚’è©¦è¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
        models_to_try = [self.model_config.name] + self.model_config.fallback_models

        for model_name in models_to_try:
            try:
                # æœ€æ–°ã®APIã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«ã¯åŸºæœ¬æƒ…å ±ã®ã¿æ¸¡ã™
                model = genai.GenerativeModel(model_name=model_name)

                # è»½é‡ãªãƒ†ã‚¹ãƒˆã§ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                logger.info(f"Successfully created model: {model_name}")
                self.model_config.name = model_name  # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã‚’æ›´æ–°
                return model

            except Exception as e:
                logger.warning(f"Failed to create model {model_name}: {e}")
                continue

        raise ValueError(f"All models failed: {models_to_try}")

    def _prepare_generation_config(self):
        """ç”Ÿæˆè¨­å®šã‚’æº–å‚™"""
        return self.model_config.generation_config

    def _prepare_safety_settings(self):
        """å®‰å…¨è¨­å®šã‚’æº–å‚™"""
        safety_settings = []
        for category, threshold in self.model_config.safety_settings.items():
            try:
                safety_settings.append(
                    {
                        "category": getattr(HarmCategory, category),
                        "threshold": getattr(HarmBlockThreshold, threshold),
                    }
                )
            except AttributeError as e:
                logger.warning(
                    f"Invalid safety setting: {category}={threshold}, skipping: {e}"
                )
                continue
        return safety_settings

    def detect_vad_segments(self, audio_path: str) -> List[Dict]:
        """
        VAD (Voice Activity Detection) ã§ã‚¹ãƒ”ãƒ¼ãƒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡º

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            List[Dict]: éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"Detecting speech segments in: {audio_path}")

        try:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio = AudioSegment.from_file(audio_path)

            # 16kHz, monoã«å¤‰æ›ï¼ˆGemini APIã®æ¨å¥¨å½¢å¼ï¼‰
            audio = audio.set_frame_rate(16000).set_channels(1)

            # pydubã®ç„¡éŸ³æ¤œçŸ¥ã‚’ä½¿ç”¨
            # ç„¡éŸ³ã§ãªã„éƒ¨åˆ†ã‚’æ¤œå‡ºï¼ˆæœ€å°é•·1ç§’ã€ç„¡éŸ³é–¾å€¤-40dBï¼‰
            nonsilent_ranges = detect_nonsilent(
                audio,
                min_silence_len=1000,  # 1ç§’ä»¥ä¸Šã®ç„¡éŸ³
                silence_thresh=-40,  # -40dBä»¥ä¸‹ã‚’ç„¡éŸ³ã¨ã™ã‚‹
                seek_step=100,  # 100mså˜ä½ã§æ¤œç´¢
            )

            segments = []
            for i, (start_ms, end_ms) in enumerate(nonsilent_ranges):
                segments.append(
                    {
                        "segment_id": i,
                        "start_ms": start_ms,
                        "end_ms": end_ms,
                        "duration_ms": end_ms - start_ms,
                        "start_sec": start_ms / 1000.0,
                        "end_sec": end_ms / 1000.0,
                        "duration_sec": (end_ms - start_ms) / 1000.0,
                    }
                )

            logger.info(f"Detected {len(segments)} speech segments")
            return segments

        except Exception as e:
            logger.error(f"VAD detection failed: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ä½“ã‚’1ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
            audio = AudioSegment.from_file(audio_path)
            duration_ms = len(audio)
            return [
                {
                    "segment_id": 0,
                    "start_ms": 0,
                    "end_ms": duration_ms,
                    "duration_ms": duration_ms,
                    "start_sec": 0.0,
                    "end_sec": duration_ms / 1000.0,
                    "duration_sec": duration_ms / 1000.0,
                }
            ]

    def create_dynamic_chunks(self, audio_path: str) -> List[ChunkMetadata]:
        """
        å‹•çš„ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆVAD + ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™è€ƒæ…®ï¼‰

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            List[ChunkMetadata]: ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        logger.info("Creating dynamic chunks...")

        # VADã§ã‚¹ãƒ”ãƒ¼ãƒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡º
        segments = self.detect_vad_segments(audio_path)

        chunks = []
        current_chunk_start = 0
        current_chunk_duration = 0
        chunk_id = 0

        # ç›®æ¨™ãƒãƒ£ãƒ³ã‚¯é•·ï¼ˆç§’ï¼‰
        target_duration = self.processing_config.chunk_duration_min * 60
        max_duration = self.processing_config.chunk_duration_max * 60

        i = 0
        while i < len(segments):
            segment = segments[i]
            segment_duration = segment["duration_sec"]

            # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«è¿½åŠ ã—ãŸå ´åˆã®é•·ã•
            new_duration = current_chunk_duration + segment_duration

            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®åˆ¤å®š
            should_split = False

            if new_duration > max_duration:
                # æœ€å¤§é•·ã‚’è¶…ãˆã‚‹å ´åˆã¯å¿…ãšåˆ†å‰²
                should_split = True
            elif new_duration > target_duration:
                # ç›®æ¨™é•·ã‚’è¶…ãˆãŸå ´åˆã€æ¬¡ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®å¢ƒç•Œã§åˆ†å‰²
                should_split = True
            elif current_chunk_duration == 0:
                # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯å¿…ãšå«ã‚ã‚‹
                should_split = False

            if should_split and current_chunk_duration > 0:
                # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç¢ºå®š
                chunk_end = current_chunk_start + current_chunk_duration
                chunk = self._create_chunk_file(
                    audio_path, chunk_id, current_chunk_start, chunk_end
                )
                chunks.append(chunk)

                # æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã®æº–å‚™
                chunk_id += 1
                current_chunk_start = segment["start_sec"]
                current_chunk_duration = segment_duration
            else:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã«è¿½åŠ 
                if current_chunk_duration == 0:
                    current_chunk_start = segment["start_sec"]
                current_chunk_duration = segment["end_sec"] - current_chunk_start

            i += 1

        # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
        if current_chunk_duration > 0:
            chunk_end = current_chunk_start + current_chunk_duration
            chunk = self._create_chunk_file(
                audio_path, chunk_id, current_chunk_start, chunk_end
            )
            chunks.append(chunk)

        logger.info(f"Created {len(chunks)} dynamic chunks")
        return chunks

    def _create_chunk_file(
        self, audio_path: str, chunk_id: int, start_sec: float, end_sec: float
    ) -> ChunkMetadata:
        """
        éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ

        Args:
            audio_path: å…ƒã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            chunk_id: ãƒãƒ£ãƒ³ã‚¯ID
            start_sec: é–‹å§‹æ™‚åˆ»ï¼ˆç§’ï¼‰
            end_sec: çµ‚äº†æ™‚åˆ»ï¼ˆç§’ï¼‰

        Returns:
            ChunkMetadata: ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            audio = AudioSegment.from_file(audio_path)

            # æŒ‡å®šç¯„å›²ã‚’åˆ‡ã‚Šå‡ºã—
            start_ms = int(start_sec * 1000)
            end_ms = int(end_sec * 1000)
            chunk_audio = audio[start_ms:end_ms]

            # 16kHz, monoã«å¤‰æ›
            chunk_audio = chunk_audio.set_frame_rate(16000).set_channels(1)

            # ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            chunk_filename = f"chunk_{chunk_id:03d}.wav"
            chunk_path = self.chunks_dir / chunk_filename
            chunk_audio.export(chunk_path, format="wav")

            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆ1ç§’ = 32ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
            duration = end_sec - start_sec
            estimated_tokens = int(duration * 32)

            metadata = ChunkMetadata(
                chunk_id=chunk_id,
                start_time=start_sec,
                end_time=end_sec,
                duration=duration,
                file_path=str(chunk_path),
                tokens_estimated=estimated_tokens,
            )

            logger.info(
                f"Created chunk {chunk_id}: {duration:.1f}s, ~{estimated_tokens} tokens"
            )
            return metadata

        except Exception as e:
            logger.error(f"Failed to create chunk {chunk_id}: {e}")
            raise

    def extract_speakers_from_transcript(self, transcript: str) -> List[str]:
        """ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰è©±è€…ã‚’æŠ½å‡º"""
        speakers = re.findall(r"^([^:ï¼š]+)[ï¼š:]", transcript, re.MULTILINE)
        # "è‡ªåˆ†"ä»¥å¤–ã®è©±è€…ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        return [s.strip() for s in speakers if s.strip() and s.strip() != "è‡ªåˆ†"]

    def extract_key_information(self, transcript: str) -> Dict:
        """ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰é‡è¦æƒ…å ±ã‚’æŠ½å‡º"""
        info = {"decisions": [], "action_items": [], "topics": [], "references": []}

        lines = transcript.split("\n")
        for line in lines:
            # æ±ºå®šäº‹é …ã®æ¤œå‡º
            if any(keyword in line for keyword in ["æ±ºå®š", "æ±ºã¾ã‚Š", "ç¢ºå®š", "åˆæ„"]):
                info["decisions"].append(line.strip())

            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®æ¤œå‡º
            if any(
                keyword in line
                for keyword in ["TODO", "ã‚„ã‚‹ã“ã¨", "å®¿é¡Œ", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", "ã€œã™ã‚‹"]
            ):
                info["action_items"].append(line.strip())

            # æŒ‡ç¤ºèªã®æ¤œå‡º
            references = re.findall(r"(ãã‚Œ|ã“ã‚Œ|ã‚ã‚Œ|ãã®ä»¶|ã‚ã®ä»¶|å…ˆã»ã©ã®)", line)
            info["references"].extend(references)

        return info

    def update_context_from_result(self, result: Dict, context: EnhancedContext):
        """å‡¦ç†çµæœã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°"""
        if result["status"] != "completed":
            return

        # è©±è€…ã®æŠ½å‡ºã¨æ›´æ–°
        speakers = self.extract_speakers_from_transcript(result["transcript"])
        for speaker in speakers:
            if speaker not in context.speaker_mapping:
                context.speaker_mapping[speaker] = (
                    f"ãƒãƒ£ãƒ³ã‚¯{result['chunk_id']}ã§åˆç™»å ´"
                )
                context.speaker_descriptions[speaker] = ""

            # æœ€è¿‘ã®è©±è€…å±¥æ­´ã‚’æ›´æ–°
            if speaker not in context.last_speakers:
                context.last_speakers.append(speaker)
            if len(context.last_speakers) > 5:
                context.last_speakers.pop(0)

        # é‡è¦æƒ…å ±ã®æŠ½å‡º
        key_info = self.extract_key_information(result["transcript"])

        # æ±ºå®šäº‹é …ã®è¿½åŠ 
        context.key_decisions.extend(key_info["decisions"][:3])

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®è¿½åŠ 
        for item in key_info["action_items"]:
            context.action_items.append(
                {
                    "chunk_id": result["chunk_id"],
                    "content": item,
                    "timestamp": self._format_time(result["start_time"]),
                }
            )

        # æœªè§£æ±ºã®å‚ç…§ã‚’æ›´æ–°
        context.unresolved_references = key_info["references"]

        # ã‚­ãƒ¼ãƒˆãƒ”ãƒƒã‚¯ã®æ›´æ–°ï¼ˆæ–‡å­—èµ·ã“ã—ã‹ã‚‰æŠ½å‡ºï¼‰
        lines = result["transcript"].split("\n")
        topics = [line.strip() for line in lines if len(line.strip()) > 50]
        context.key_topics.extend(topics[:2])
        if len(context.key_topics) > 10:
            context.key_topics = context.key_topics[-10:]

    def format_context_for_prompt(self, context: EnhancedContext) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢"""
        context_info = f"""## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

### ã“ã‚Œã¾ã§ã®è¦ç´„
{context.rolling_summary}

### ç™»å ´äººç‰©
"""
        for speaker, first_appearance in context.speaker_mapping.items():
            desc = context.speaker_descriptions.get(speaker, "")
            context_info += f"- {speaker}: {first_appearance}"
            if desc:
                context_info += f" - {desc}"
            context_info += "\n"

        if context.key_topics:
            context_info += f"\n### è­°è«–ä¸­ã®ãƒˆãƒ”ãƒƒã‚¯\n"
            for topic in context.key_topics[-5:]:
                context_info += f"- {topic}\n"

        if context.key_decisions:
            context_info += f"\n### ã“ã‚Œã¾ã§ã®æ±ºå®šäº‹é …\n"
            for decision in context.key_decisions[-5:]:
                context_info += f"- {decision}\n"

        if context.unresolved_references:
            context_info += f"\n### æœªè§£æ±ºã®å‚ç…§\n"
            context_info += f"å‰ã®ãƒãƒ£ãƒ³ã‚¯ã§è¨€åŠã•ã‚ŒãŸå†…å®¹: {', '.join(set(context.unresolved_references))}\n"

        if context.last_speakers:
            context_info += f"\n### æœ€è¿‘ã®è©±è€…\n"
            context_info += f"ç›´å‰ã«è©±ã—ã¦ã„ãŸäºº: {', '.join(context.last_speakers)}\n"

        return context_info

    async def process_chunk(
        self, chunk: ChunkMetadata, context: EnhancedContext
    ) -> Dict:
        """
        å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®æ–‡å­—èµ·ã“ã—å‡¦ç†ï¼ˆå¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰

        Args:
            chunk: ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            context: æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            Dict: æ–‡å­—èµ·ã“ã—çµæœã®ã¿
        """
        logger.info(f"ğŸµ Processing chunk {chunk.chunk_id} ({chunk.duration:.1f}s)...")

        uploaded_file = None

        for attempt in range(self.processing_config.retry_max_attempts):
            try:
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒªãƒˆãƒ©ã‚¤ã”ã¨ã«å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
                if uploaded_file:
                    try:
                        genai.delete_file(uploaded_file.name)
                    except:
                        pass

                uploaded_file = genai.upload_file(chunk.file_path)

                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†ã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
                while uploaded_file.state.name == "PROCESSING":
                    await asyncio.sleep(1)
                    uploaded_file = genai.get_file(uploaded_file.name)

                if uploaded_file.state.name == "FAILED":
                    raise Exception(f"File upload failed for chunk {chunk.chunk_id}")

                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æ•´å½¢ï¼ˆãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ç°¡ç´ åŒ–ï¼‰
                if attempt > 0:
                    # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç°¡ç´ åŒ–ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å›é¿
                    context_info = "å‰ã®ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ã®ç¶™ç¶šã§ã™ã€‚"
                else:
                    context_info = self.format_context_for_prompt(context)

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ¥ã€ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯çŸ­ç¸®ç‰ˆï¼‰
                if self.output_config.mode == "transcript":
                    if attempt > 0:
                        # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        system_prompt = "éŸ³å£°ã‚’æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚"
                        user_prompt = "ã“ã®éŸ³å£°ã®å†…å®¹ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚"
                    else:
                        system_prompt = SYSTEM_PROMPT_TRANSCRIPT_CHUNK.format(
                            context_info=context_info, chunk_id=chunk.chunk_id
                        )
                        user_prompt = USER_PROMPT_TRANSCRIPT_CHUNK
                else:  # lifelog
                    if attempt > 0:
                        # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        system_prompt = (
                            "æ—¥å¸¸ä¼šè©±ã‚’è‡ªç„¶ãªå½¢ã§ãƒ©ã‚¤ãƒ•ãƒ­ã‚°ã¨ã—ã¦è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚"
                        )
                        user_prompt = "ã“ã®éŸ³å£°ã‚’ãƒ©ã‚¤ãƒ•ãƒ­ã‚°å½¢å¼ã§è¨˜éŒ²ã—ã¦ãã ã•ã„ã€‚"
                    else:
                        system_prompt = SYSTEM_PROMPT_LIFELOG_CHUNK.format(
                            context_info=context_info, chunk_id=chunk.chunk_id
                        )
                        user_prompt = USER_PROMPT_LIFELOG_CHUNK

                # ç”Ÿæˆè¨­å®šã¨å®‰å…¨è¨­å®šã‚’æº–å‚™ï¼ˆãƒªãƒˆãƒ©ã‚¤æ™‚ã¯æ¸©åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
                generation_config = self._prepare_generation_config()
                if attempt > 0:
                    generation_config["temperature"] = max(
                        0.0, generation_config["temperature"] - 0.05 * attempt
                    )

                safety_settings = self._prepare_safety_settings()

                # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                response = self.model.generate_content(
                    contents=[
                        f"System: {system_prompt}" if system_prompt else "",
                        user_prompt,
                        uploaded_file,
                    ],
                    generation_config=generation_config,
                    safety_settings=safety_settings,
                )

                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
                if not response.candidates:
                    raise Exception("No candidates in response")

                candidate = response.candidates[0]
                finish_reason = candidate.finish_reason

                if finish_reason == 2:  # SAFETY
                    logger.warning(
                        f"ğŸ›¡ï¸ Safety filter triggered for chunk {chunk.chunk_id}, attempt {attempt + 1}"
                    )
                    if attempt < self.processing_config.retry_max_attempts - 1:
                        await asyncio.sleep(
                            self.processing_config.retry_backoff_sec * (2**attempt)
                        )
                        continue
                    else:
                        # æœ€å¾Œã®è©¦è¡Œã§ã¯éƒ¨åˆ†çš„ãªçµæœã‚’ç”Ÿæˆ
                        transcript = f"[éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ {chunk.chunk_id}: å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Šå†…å®¹ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“]"
                elif finish_reason == 3:  # RECITATION
                    logger.warning(f"ğŸ”„ Recitation detected for chunk {chunk.chunk_id}")
                    transcript = f"[éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ {chunk.chunk_id}: æ—¢çŸ¥ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ]"
                elif finish_reason == 1:  # STOP (æ­£å¸¸çµ‚äº†)
                    transcript = response.text
                else:
                    transcript = (
                        response.text
                        if hasattr(response, "text")
                        else f"[éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ {chunk.chunk_id}: å‡¦ç†ãŒä¸å®Œå…¨ã§ã™]"
                    )

                # æˆåŠŸæ™‚ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if uploaded_file:
                    try:
                        genai.delete_file(uploaded_file.name)
                    except:
                        pass

                result = {
                    "chunk_id": chunk.chunk_id,
                    "transcript": transcript,
                    "start_time": chunk.start_time,
                    "end_time": chunk.end_time,
                    "duration": chunk.duration,
                    "status": "completed" if finish_reason == 1 else "partial",
                    "finish_reason": finish_reason,
                    "attempts": attempt + 1,
                }

                logger.info(
                    f"âœ… Completed chunk {chunk.chunk_id} (attempt {attempt + 1}, reason: {finish_reason})"
                )
                return result

            except Exception as e:
                error_msg = str(e)
                logger.warning(
                    f"âš ï¸ Attempt {attempt + 1} failed for chunk {chunk.chunk_id}: {error_msg}"
                )

                if attempt < self.processing_config.retry_max_attempts - 1:
                    wait_time = self.processing_config.retry_backoff_sec * (2**attempt)
                    logger.info(f"ğŸ”„ Retrying in {wait_time}s...")
                    await asyncio.sleep(wait_time)
                else:
                    # æœ€çµ‚è©¦è¡Œå¤±æ•—æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    if uploaded_file:
                        try:
                            genai.delete_file(uploaded_file.name)
                        except:
                            pass

                    # è‡´å‘½çš„ã§ãªã„å ´åˆã¯éƒ¨åˆ†çš„ãªçµæœã‚’è¿”ã™
                    logger.error(
                        f"âŒ Final attempt failed for chunk {chunk.chunk_id}: {error_msg}"
                    )
                    return {
                        "chunk_id": chunk.chunk_id,
                        "transcript": f"[éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ {chunk.chunk_id}: å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ]",
                        "start_time": chunk.start_time,
                        "end_time": chunk.end_time,
                        "duration": chunk.duration,
                        "status": "failed",
                        "error": error_msg,
                        "attempts": attempt + 1,
                    }

    def compress_rolling_summary(self, current_summary: str, new_content: str) -> str:
        """
        ãƒ­ãƒ¼ãƒªãƒ³ã‚°è¦ç´„ã®åœ§ç¸®

        Args:
            current_summary: ç¾åœ¨ã®è¦ç´„
            new_content: æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

        Returns:
            str: åœ§ç¸®ã•ã‚ŒãŸè¦ç´„
        """
        if not current_summary:
            return new_content[: self.processing_config.rolling_summary_tokens]

        # æ—¢å­˜è¦ç´„ã¨æ–°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµåˆ
        combined = f"{current_summary}\n\n{new_content}"

        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è¶…ãˆã‚‹å ´åˆã¯åœ§ç¸®
        if len(combined) > self.processing_config.rolling_summary_tokens:
            try:
                compress_prompt = f"""
                ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’{self.processing_config.rolling_summary_tokens}æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
                é‡è¦ãªäº‹å®Ÿã€æ±ºå®šäº‹é …ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€è©±è€…ã®æƒ…å ±ã‚’å¿…ãšä¿æŒã—ã¦ãã ã•ã„ã€‚

                {combined}
                """

                response = self.model.generate_content(
                    contents=[compress_prompt],
                    generation_config=self._prepare_generation_config(),
                    safety_settings=self._prepare_safety_settings(),
                )
                compressed = response.text[
                    : self.processing_config.rolling_summary_tokens
                ]
                logger.info("Rolling summary compressed")
                return compressed

            except Exception as e:
                logger.warning(f"Summary compression failed: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”ãªåˆ‡ã‚Šè©°ã‚
                return combined[: self.processing_config.rolling_summary_tokens]

        return combined

    def save_checkpoint(self, state: ProcessingState):
        """å‡¦ç†çŠ¶æ…‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        checkpoint_path = (
            self.checkpoints_dir / f"checkpoint_{state.mode}_{state.timestamp}.pkl"
        )
        try:
            with open(checkpoint_path, "wb") as f:
                pickle.dump(state, f)
            logger.info(f"Checkpoint saved: {checkpoint_path}")
        except Exception as e:
            logger.error(f"Failed to save checkpoint: {e}")

    def load_latest_checkpoint(self, mode: str) -> Optional[ProcessingState]:
        """æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        checkpoints = list(self.checkpoints_dir.glob(f"checkpoint_{mode}_*.pkl"))
        if not checkpoints:
            return None

        latest = max(checkpoints, key=lambda p: p.stat().st_mtime)
        try:
            with open(latest, "rb") as f:
                state = pickle.load(f)
            logger.info(f"Checkpoint loaded: {latest}")
            return state
        except Exception as e:
            logger.error(f"Failed to load checkpoint: {e}")
            return None

    async def process_audio_pipeline(
        self, audio_path: str, resume: bool = False
    ) -> Dict:
        """
        éŸ³å£°å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            resume: ä¸­æ–­ã—ãŸã¨ã“ã‚ã‹ã‚‰å†é–‹ã™ã‚‹ã‹

        Returns:
            Dict: å‡¦ç†çµæœ
        """
        logger.info(f"Starting audio processing pipeline for: {audio_path}")

        # ç¾åœ¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜ï¼ˆæ™‚åˆ»è¨ˆç®—ç”¨ï¼‰
        self.current_audio_path = audio_path

        try:
            # å‡¦ç†çŠ¶æ…‹ã®åˆæœŸåŒ–ã¾ãŸã¯å¾©å…ƒ
            if resume:
                state = self.load_latest_checkpoint(self.output_config.mode)
                if state and state.audio_path == audio_path:
                    self.context = state.context
                    all_results = state.results
                    logger.info(f"Resuming from chunk {len(state.completed_chunks)}")
                else:
                    logger.warning("No valid checkpoint found. Starting fresh.")
                    resume = False

            if not resume:
                state = ProcessingState(
                    audio_path=audio_path,
                    mode=self.output_config.mode,
                    timestamp=datetime.now().strftime("%Y%m%d_%H%M%S"),
                )
                all_results = []

            # ã‚¹ãƒ†ãƒƒãƒ—1: å‹•çš„ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self.create_dynamic_chunks(audio_path)

            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒ£ãƒ³ã‚¯ã‚’é †æ¬¡æ–‡å­—èµ·ã“ã—ï¼ˆæ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºä»˜ãï¼‰
            total_chunks = len(chunks)
            completed_count = 0
            success_count = 0
            partial_count = 0
            failed_count = 0

            logger.info(f"ğŸ“Š Processing {total_chunks} chunks...")

            for chunk in chunks:
                # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®ãƒãƒ£ãƒ³ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
                if resume and chunk.chunk_id in state.completed_chunks:
                    logger.info(f"â­ï¸ Skipping already processed chunk {chunk.chunk_id}")
                    completed_count += 1
                    continue

                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
                progress = (completed_count / total_chunks) * 100
                logger.info(
                    f"ğŸ“ˆ Progress: {progress:.1f}% ({completed_count}/{total_chunks})"
                )

                result = await self.process_chunk(chunk, self.context)
                all_results.append(result)

                # çµæœã®çµ±è¨ˆã‚’æ›´æ–°
                completed_count += 1
                if result["status"] == "completed":
                    success_count += 1
                    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆè¦ç´„ãªã—ã§åŸºæœ¬æƒ…å ±ã®ã¿ï¼‰
                    self.update_context_from_result(result, self.context)
                elif result["status"] == "partial":
                    partial_count += 1
                else:
                    failed_count += 1

                # å‡¦ç†çŠ¶æ…‹ã‚’æ›´æ–°
                state.completed_chunks.append(chunk.chunk_id)
                state.context = self.context
                state.results = all_results

                # å®šæœŸçš„ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆ5ãƒãƒ£ãƒ³ã‚¯ã”ã¨ï¼‰
                if len(state.completed_chunks) % 5 == 0:
                    self.save_checkpoint(state)
                    logger.info(
                        f"ğŸ’¾ Checkpoint saved (Success: {success_count}, Partial: {partial_count}, Failed: {failed_count})"
                    )

                # æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å‰ã®çŸ­ã„å¾…æ©Ÿ
                await asyncio.sleep(0.5)

            # æœ€çµ‚çµ±è¨ˆã®å ±å‘Š
            success_rate = (
                (success_count / total_chunks) * 100 if total_chunks > 0 else 0
            )
            logger.info(f"ğŸ¯ Processing completed!")
            logger.info(
                f"   âœ… Success: {success_count}/{total_chunks} ({success_rate:.1f}%)"
            )
            logger.info(f"   âš ï¸ Partial: {partial_count}/{total_chunks}")
            logger.info(f"   âŒ Failed: {failed_count}/{total_chunks}")

            if failed_count > total_chunks * 0.5:
                logger.warning(
                    "âš ï¸ High failure rate detected. Consider reviewing chunk size or content."
                )
            elif success_rate >= 90:
                logger.info("ğŸ† Excellent processing quality!")

            # ã‚¹ãƒ†ãƒƒãƒ—3: ç°¡æ˜“çš„ãªãƒ­ãƒ¼ãƒªãƒ³ã‚°è¦ç´„ã‚’æ–‡å­—èµ·ã“ã—ã‹ã‚‰ä½œæˆ
            for result in all_results:
                if result["status"] == "completed":
                    # æ–‡å­—èµ·ã“ã—ã®æœ€åˆã®200æ–‡å­—ã‚’ç°¡æ˜“è¦ç´„ã¨ã—ã¦ä½¿ç”¨
                    simple_summary = result["transcript"][:200].replace("\n", " ")
                    self.context.rolling_summary = self.compress_rolling_summary(
                        self.context.rolling_summary, simple_summary
                    )

            # ã‚¹ãƒ†ãƒƒãƒ—4: çµæœã®é›†ç´„ã¨å‡ºåŠ›ç”Ÿæˆ
            output_results = await self.generate_outputs(all_results, audio_path)

            logger.info("Audio processing pipeline completed successfully")
            return output_results

        except Exception as e:
            logger.error(f"Pipeline failed: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
            if "state" in locals():
                self.save_checkpoint(state)
            raise

    async def generate_outputs(self, results: List[Dict], audio_path: str) -> Dict:
        """
        æœ€çµ‚å‡ºåŠ›ã®ç”Ÿæˆ

        Args:
            results: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
            audio_path: å…ƒã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            Dict: ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        """
        logger.info(f"Generating output for mode: {self.output_config.mode}")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = Path(self.output_config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        output_files = {}

        # ãƒ¢ãƒ¼ãƒ‰åˆ¥å‡ºåŠ›ç”Ÿæˆ
        if self.output_config.mode == "transcript":
            content = self._generate_transcript_output(results)
            output_file = output_dir / "transcript.md"

            # è©±è€…ä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”Ÿæˆ
            speaker_info = self._generate_speaker_info()
            speaker_file = output_dir / "speakers.json"
            with open(speaker_file, "w", encoding="utf-8") as f:
                json.dump(speaker_info, f, ensure_ascii=False, indent=2)
            output_files["speakers"] = str(speaker_file)

        else:  # lifelog
            content = self._generate_lifelog_output(results)
            output_file = output_dir / "lifelog.md"

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(content)

        output_files[self.output_config.mode] = str(output_file)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚‚ä¿å­˜
        context_file = output_dir / "context.json"
        with open(context_file, "w", encoding="utf-8") as f:
            json.dump(asdict(self.context), f, ensure_ascii=False, indent=2)
        output_files["context"] = str(context_file)

        logger.info(f"Generated {self.output_config.mode}: {output_file}")

        return output_files

    def _generate_speaker_info(self) -> Dict:
        """è©±è€…æƒ…å ±ã‚’ç”Ÿæˆ"""
        speaker_info = {
            "total_speakers": len(self.context.speaker_mapping),
            "speakers": {},
        }

        for speaker, info in self.context.speaker_mapping.items():
            speaker_info["speakers"][speaker] = {
                "first_appearance": info,
                "description": self.context.speaker_descriptions.get(speaker, ""),
                "is_recent": speaker in self.context.last_speakers,
            }

        return speaker_info

    def _generate_transcript_output(self, results: List[Dict]) -> str:
        """å…¨æ–‡æ–‡å­—èµ·ã“ã—ãƒ¢ãƒ¼ãƒ‰ã®å‡ºåŠ›ç”Ÿæˆï¼ˆå“è³ªçµ±è¨ˆä»˜ãï¼‰"""
        # å‡¦ç†çµ±è¨ˆã®è¨ˆç®—
        total_chunks = len(results)
        success_chunks = len([r for r in results if r["status"] == "completed"])
        partial_chunks = len([r for r in results if r["status"] == "partial"])
        failed_chunks = len([r for r in results if r["status"] == "failed"])
        success_rate = (success_chunks / total_chunks * 100) if total_chunks > 0 else 0

        content = f"""# éŸ³å£°æ–‡å­—èµ·ã“ã—

## å‡¦ç†æƒ…å ±
- å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ¢ãƒ‡ãƒ«: {self.model_config.name}
- ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}
- å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: å…¨æ–‡æ–‡å­—èµ·ã“ã—
- è­˜åˆ¥ã•ã‚ŒãŸè©±è€…æ•°: {len(self.context.speaker_mapping)}
- å‡¦ç†å“è³ª: âœ…æˆåŠŸ {success_chunks}, âš ï¸éƒ¨åˆ† {partial_chunks}, âŒå¤±æ•— {failed_chunks} (æˆåŠŸç‡: {success_rate:.1f}%)

## è©±è€…ä¸€è¦§
"""
        if self.context.speaker_mapping:
            for speaker, info in self.context.speaker_mapping.items():
                content += f"- **{speaker}**: {info}\n"
        else:
            content += "è©±è€…ãŒè­˜åˆ¥ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"

        if self.context.key_decisions:
            content += "\n## ä¸»è¦ãªæ±ºå®šäº‹é …\n"
            for decision in self.context.key_decisions[-5:]:
                content += f"- {decision}\n"

        if self.context.action_items:
            content += "\n## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ \n"
            for item in self.context.action_items:
                content += f"- [{item['timestamp']}] {item['content']}\n"

        content += "\n## æ–‡å­—èµ·ã“ã—å†…å®¹\n\n"

        for result in results:
            start_time = self._format_time(
                result["start_time"], self.current_audio_path
            )
            end_time = self._format_time(result["end_time"], self.current_audio_path)

            # ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
            status_icon = (
                "âœ…"
                if result["status"] == "completed"
                else "âš ï¸" if result["status"] == "partial" else "âŒ"
            )
            content += f"### [{start_time} - {end_time}] {status_icon}\n\n"

            if result["status"] == "completed" and result["transcript"]:
                content += f"{result['transcript']}\n\n"
            elif result["status"] == "partial" and result["transcript"]:
                content += f"{result['transcript']}\n\n"
                content += (
                    "*ï¼ˆæ³¨ï¼šã“ã®éƒ¨åˆ†ã¯å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¾ãŸã¯éƒ¨åˆ†çš„ãªå‡¦ç†çµæœã§ã™ï¼‰*\n\n"
                )
            elif result["status"] == "failed":
                error_info = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                content += f"âŒ **å‡¦ç†ã‚¨ãƒ©ãƒ¼**: {error_info}\n\n"
                content += f"*ãƒªãƒˆãƒ©ã‚¤å›æ•°: {result.get('attempts', 'N/A')}å›*\n\n"
            else:
                content += "ã“ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã«ã¯ç™ºè©±å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n"

        # å‡¦ç†å®Œäº†ã®æ³¨è¨˜
        if failed_chunks > 0:
            content += "## æ³¨è¨˜\n\n"
            content += f"âš ï¸ {failed_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
            content += "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã‹ã€éŸ³å£°å“è³ªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"

        return content

    def _generate_lifelog_output(self, results: List[Dict]) -> str:
        """ãƒ©ã‚¤ãƒ•ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰ã®å‡ºåŠ›ç”Ÿæˆï¼ˆå“è³ªçµ±è¨ˆä»˜ãï¼‰"""
        # å‡¦ç†çµ±è¨ˆã®è¨ˆç®—
        total_chunks = len(results)
        success_chunks = len([r for r in results if r["status"] == "completed"])
        partial_chunks = len([r for r in results if r["status"] == "partial"])
        failed_chunks = len([r for r in results if r["status"] == "failed"])
        success_rate = (success_chunks / total_chunks * 100) if total_chunks > 0 else 0

        content = f"""# ãƒ©ã‚¤ãƒ•ãƒ­ã‚°è¨˜éŒ²

## å‡¦ç†æƒ…å ±
- å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ¢ãƒ‡ãƒ«: {self.model_config.name}
- ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks}
- å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: ãƒ©ã‚¤ãƒ•ãƒ­ã‚°
- å‡¦ç†å“è³ª: âœ…æˆåŠŸ {success_chunks}, âš ï¸éƒ¨åˆ† {partial_chunks}, âŒå¤±æ•— {failed_chunks} (æˆåŠŸç‡: {success_rate:.1f}%)

## æ™‚ç³»åˆ—ãƒ©ã‚¤ãƒ•ãƒ­ã‚°

"""

        for result in results:
            start_time = self._format_time(
                result["start_time"], self.current_audio_path
            )
            end_time = self._format_time(result["end_time"], self.current_audio_path)

            # ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
            status_icon = (
                "âœ…"
                if result["status"] == "completed"
                else "âš ï¸" if result["status"] == "partial" else "âŒ"
            )
            content += f"### [{start_time} - {end_time}] {status_icon}\n\n"

            if result["status"] == "completed" and result["transcript"]:
                content += f"{result['transcript']}\n\n"
            elif result["status"] == "partial" and result["transcript"]:
                content += f"{result['transcript']}\n\n"
                content += (
                    "*ï¼ˆæ³¨ï¼šã“ã®éƒ¨åˆ†ã¯å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¾ãŸã¯éƒ¨åˆ†çš„ãªå‡¦ç†çµæœã§ã™ï¼‰*\n\n"
                )
            elif result["status"] == "failed":
                error_info = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                content += f"âŒ **å‡¦ç†ã‚¨ãƒ©ãƒ¼**: {error_info}\n\n"
                content += f"*ãƒªãƒˆãƒ©ã‚¤å›æ•°: {result.get('attempts', 'N/A')}å›*\n\n"
            else:
                content += "ï¼ˆç„¡éŸ³åŒºé–“ï¼‰\n\n"

            content += "---\n\n"

        # å‡¦ç†å®Œäº†ã®æ³¨è¨˜
        if failed_chunks > 0:
            content += "## æ³¨è¨˜\n\n"
            content += f"âš ï¸ {failed_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
            content += "éŸ³å£°å“è³ªã‚„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"

        return content

    def _extract_start_time_from_filename(self, audio_path: str) -> Optional[datetime]:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰é–‹å§‹æ™‚åˆ»ã‚’æŠ½å‡º

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            datetime: é–‹å§‹æ™‚åˆ»ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã—ãªã„å ´åˆã¯Noneï¼‰

        Examples:
            "2025-06-28_02_40_22.mp3" -> datetime(2025, 6, 28, 2, 40, 22)
        """
        import re

        filename = Path(audio_path).stem

        # ãƒ‘ã‚¿ãƒ¼ãƒ³: YYYY-MM-DD_HH_MM_SS (ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹/ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹å¯¾å¿œ)
        pattern = r"(\d{4})-(\d{2})-(\d{2})_(\d{2})_(\d{2})_(\d{2})"
        match = re.search(pattern, filename)

        if match:
            year, month, day, hour, minute, second = map(int, match.groups())
            try:
                return datetime(year, month, day, hour, minute, second)
            except ValueError:
                logger.warning(f"Invalid datetime in filename: {filename}")
                return None
        else:
            logger.debug(f"Filename pattern not matched: {filename}")
            return None

    def _format_time(self, seconds: float, audio_path: str = None) -> str:
        """
        æ™‚åˆ»ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

        Args:
            seconds: çµŒéç§’æ•°
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ©ã‚¤ãƒ•ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿæ™‚é–“è¨ˆç®—ã«ä½¿ç”¨ï¼‰

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ™‚åˆ»
                transcriptãƒ¢ãƒ¼ãƒ‰: MM:SSå½¢å¼
                lifelogãƒ¢ãƒ¼ãƒ‰: HH:MM:SSå½¢å¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰é–‹å§‹æ™‚åˆ»ã‚’å–å¾—ã§ããŸå ´åˆï¼‰
        """
        # transcriptãƒ¢ãƒ¼ãƒ‰ã¯å¾“æ¥é€šã‚Šç›¸å¯¾æ™‚é–“
        if self.output_config.mode == "transcript":
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes:02d}:{secs:02d}"

        # lifelogãƒ¢ãƒ¼ãƒ‰ã§å®Ÿæ™‚é–“è¨ˆç®—ã‚’è©¦è¡Œ
        if self.output_config.mode == "lifelog" and audio_path:
            start_time = self._extract_start_time_from_filename(audio_path)
            if start_time:
                # é–‹å§‹æ™‚åˆ»ã«çµŒéç§’æ•°ã‚’åŠ ç®—
                actual_time = start_time + timedelta(seconds=seconds)
                return actual_time.strftime("%H:%M:%S")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›¸å¯¾æ™‚é–“è¡¨ç¤º
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"

    async def process_audio_file(self, audio_path: str, resume: bool = False) -> Dict:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆå…¬é–‹APIï¼‰

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            resume: ä¸­æ–­ã—ãŸã¨ã“ã‚ã‹ã‚‰å†é–‹ã™ã‚‹ã‹

        Returns:
            Dict: å‡¦ç†çµæœ
        """
        if not Path(audio_path).exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")

        logger.info(f"Processing audio file: {audio_path}")
        start_time = datetime.now()

        try:
            result = await self.process_audio_pipeline(audio_path, resume)

            processing_time = datetime.now() - start_time
            result["processing_time"] = str(processing_time)
            result["status"] = "success"

            logger.info(f"Successfully processed {audio_path} in {processing_time}")
            return result

        except Exception as e:
            logger.error(f"Failed to process {audio_path}: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "processing_time": str(datetime.now() - start_time),
            }


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Voice2Structured: éŸ³å£°æ–‡å­—èµ·ã“ã—å°‚ç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"
    )
    parser.add_argument("audio_file", nargs="?", help="å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--config", default="config.yaml", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")

    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    parser.add_argument(
        "--mode",
        choices=["transcript", "lifelog"],
        default="transcript",
        help="å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: transcript (å…¨æ–‡æ–‡å­—èµ·ã“ã—) or lifelog (ãƒ©ã‚¤ãƒ•ãƒ­ã‚°)",
    )

    # å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--resume",
        action="store_true",
        help="ä¸­æ–­ã—ãŸå‡¦ç†ã‚’å†é–‹ã™ã‚‹",
    )

    # è¨­å®šãƒã‚§ãƒƒã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--check-config",
        action="store_true",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å•é¡Œã‚’å ±å‘Šã™ã‚‹",
    )

    args = parser.parse_args()

    try:
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–
        processor = Voice2Structured(args.config)

        # è¨­å®šãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
        if args.check_config:
            print("ğŸ” è¨­å®šãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
            issues = processor.validate_configuration()

            print("\nğŸ“‹ è¨­å®šãƒã‚§ãƒƒã‚¯çµæœ:")
            for issue in issues:
                print(f"  {issue}")

            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯çµ‚äº†
            error_count = sum(1 for issue in issues if issue.startswith("âŒ"))
            if error_count > 0:
                print(
                    f"\nâŒ {error_count}å€‹ã®å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )
                sys.exit(1)
            else:
                print("\nâœ… è¨­å®šãƒã‚§ãƒƒã‚¯å®Œäº†ï¼å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ãªå ´åˆã®ãƒã‚§ãƒƒã‚¯
        if not args.audio_file:
            print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: --check-config ã§è¨­å®šã‚’ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚")
            sys.exit(1)

        # ãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®š
        processor.output_config.mode = args.mode

        # éåŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ
        result = asyncio.run(processor.process_audio_file(args.audio_file, args.resume))

        if result["status"] == "success":
            print("âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!")
            print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {processor.output_config.output_dir}")
            print(f"ğŸ¯ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {args.mode}")
            for output_type, file_path in result.items():
                if output_type not in ["status", "processing_time"]:
                    print(f"ğŸ“„ {output_type}: {file_path}")
        else:
            print(f"âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nâš ï¸  å‡¦ç†ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: --resume ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ç¶šãã‹ã‚‰å†é–‹ã§ãã¾ã™")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
